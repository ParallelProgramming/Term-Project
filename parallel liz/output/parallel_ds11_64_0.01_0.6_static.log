--------------------------------------------------------------------------
WARNING: It appears that your OpenFabrics subsystem is configured to only
allow registering part of your physical memory.  This can cause MPI jobs to
run with erratic performance, hang, and/or crash.

This may be caused by your OpenFabrics vendor limiting the amount of
physical memory that can be registered.  You should investigate the
relevant Linux kernel module parameters that control how much physical
memory can be registered, and increase them to allow registering all
physical memory on your machine.

See this Open MPI FAQ item for more information on these Linux kernel module
parameters:

    http://www.open-mpi.org/faq/?category=openfabrics#ib-locked-pages

  Local host:              orc389
  Registerable memory:     65536 MiB
  Total memory:            131037 MiB

Your MPI job will continue, but may be behave poorly and/or hang.
--------------------------------------------------------------------------
[orc369:04193] 1 more process has sent help message help-mpi-btl-openib.txt / reg mem limit low
[orc369:04193] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
2017-11-28 23:49:56: Running apriori with support 1.0% and confidence 60.0%
2017-11-28 23:49:56: Executing static parallel version on 64 processors
2017-11-28 23:50:05: Found 4 levels.
2017-11-28 23:50:05: Level 1  - 70 frequent itemsets
2017-11-28 23:50:05: Level 2  - 58 frequent itemsets
2017-11-28 23:50:05: Level 3  - 25 frequent itemsets
2017-11-28 23:50:05: Level 4  - 6 frequent itemsets
2017-11-28 23:50:05: Found 90 rules.
2017-11-28 23:50:05: ['170', '48']->['39'],support=0.014,confidence=0.775,lift=1.348
2017-11-28 23:50:05: ['237']->['39'],support=0.022,confidence=0.636,lift=1.107
2017-11-28 23:50:05: ['89']->['39'],support=0.031,confidence=0.716,lift=1.246
2017-11-28 23:50:05: ['237', '39']->['48'],support=0.014,confidence=0.645,lift=1.349
2017-11-28 23:50:05: ['101']->['39'],support=0.016,confidence=0.626,lift=1.089
2017-11-28 23:50:05: ['237', '48']->['39'],support=0.014,confidence=0.740,lift=1.287
2017-11-28 23:50:05: ['310', '39']->['48'],support=0.015,confidence=0.727,lift=1.522
2017-11-28 23:50:05: ['65']->['39'],support=0.032,confidence=0.623,lift=1.084
2017-11-28 23:50:05: ['310']->['48'],support=0.019,confidence=0.652,lift=1.365
2017-11-28 23:50:05: ['41']->['48'],support=0.102,confidence=0.603,lift=1.263
2017-11-28 23:50:05: ['32', '38', '39']->['48'],support=0.014,confidence=0.672,lift=1.406
2017-11-28 23:50:05: ['110']->['38'],support=0.031,confidence=0.975,lift=5.513
2017-11-28 23:50:05: ['32', '41']->['39'],support=0.027,confidence=0.738,lift=1.284
2017-11-28 23:50:05: ['110', '39', '48']->['38'],support=0.012,confidence=0.994,lift=5.620
2017-11-28 23:50:05: ['110', '39']->['38'],support=0.020,confidence=0.989,lift=5.592
2017-11-28 23:50:05: ['36', '48']->['38', '39'],support=0.012,confidence=0.763,lift=6.500
2017-11-28 23:50:05: ['89']->['48'],support=0.032,confidence=0.729,lift=1.526
2017-11-28 23:50:05: ['110']->['38', '39'],support=0.020,confidence=0.623,lift=5.307
2017-11-28 23:50:05: ['110', '48']->['38', '39'],support=0.012,confidence=0.747,lift=6.367
2017-11-28 23:50:05: ['310']->['39'],support=0.021,confidence=0.714,lift=1.242
2017-11-28 23:50:05: ['38', '41']->['48'],support=0.027,confidence=0.609,lift=1.275
2017-11-28 23:50:05: ['38', '41']->['39'],support=0.035,confidence=0.783,lift=1.362
2017-11-28 23:50:05: ['438']->['39'],support=0.014,confidence=0.676,lift=1.177
2017-11-28 23:50:05: ['2238']->['39'],support=0.015,confidence=0.750,lift=1.306
2017-11-28 23:50:05: ['110']->['39'],support=0.020,confidence=0.630,lift=1.095
2017-11-28 23:50:05: ['170']->['39'],support=0.023,confidence=0.664,lift=1.156
2017-11-28 23:50:05: ['170']->['38', '39'],support=0.023,confidence=0.652,lift=5.552
2017-11-28 23:50:05: ['475', '48']->['39'],support=0.012,confidence=0.765,lift=1.330
2017-11-28 23:50:05: ['36']->['39'],support=0.023,confidence=0.694,lift=1.207
2017-11-28 23:50:05: ['39', '89']->['48'],support=0.024,confidence=0.773,lift=1.617
2017-11-28 23:50:05: ['110', '38', '48']->['39'],support=0.012,confidence=0.758,lift=1.318
2017-11-28 23:50:05: ['36']->['38', '39'],support=0.022,confidence=0.662,lift=5.646
2017-11-28 23:50:05: ['271']->['39'],support=0.016,confidence=0.685,lift=1.191
2017-11-28 23:50:05: ['12925']->['39'],support=0.011,confidence=0.639,lift=1.112
2017-11-28 23:50:05: ['533']->['39'],support=0.010,confidence=0.620,lift=1.079
2017-11-28 23:50:05: ['36', '38', '48']->['39'],support=0.012,confidence=0.794,lift=1.382
2017-11-28 23:50:05: ['310', '48']->['39'],support=0.015,confidence=0.796,lift=1.385
2017-11-28 23:50:05: ['32', '38']->['39'],support=0.021,confidence=0.649,lift=1.130
2017-11-28 23:50:05: ['48', '65']->['39'],support=0.020,confidence=0.711,lift=1.236
2017-11-28 23:50:05: ['32', '48']->['39'],support=0.061,confidence=0.672,lift=1.170
2017-11-28 23:50:05: ['413']->['39'],support=0.013,confidence=0.601,lift=1.046
2017-11-28 23:50:05: ['255']->['48'],support=0.012,confidence=0.717,lift=1.500
2017-11-28 23:50:05: ['255']->['39'],support=0.012,confidence=0.717,lift=1.248
2017-11-28 23:50:05: ['170', '48']->['38', '39'],support=0.014,confidence=0.766,lift=6.530
2017-11-28 23:50:05: ['36', '39']->['38'],support=0.022,confidence=0.955,lift=5.398
2017-11-28 23:50:05: ['32', '39', '41']->['48'],support=0.019,confidence=0.698,lift=1.460
2017-11-28 23:50:05: ['38', '48']->['39'],support=0.069,confidence=0.768,lift=1.336
2017-11-28 23:50:05: ['60']->['39'],support=0.011,confidence=0.660,lift=1.149
2017-11-28 23:50:05: ['48', '89']->['39'],support=0.024,confidence=0.759,lift=1.321
2017-11-28 23:50:05: ['36', '39', '48']->['38'],support=0.012,confidence=0.968,lift=5.471
2017-11-28 23:50:05: ['225', '48']->['39'],support=0.016,confidence=0.806,lift=1.403
2017-11-28 23:50:05: ['170', '48']->['38'],support=0.017,confidence=0.988,lift=5.584
2017-11-28 23:50:05: ['36', '48']->['39'],support=0.013,confidence=0.788,lift=1.371
2017-11-28 23:50:05: ['32', '38', '48']->['39'],support=0.014,confidence=0.751,lift=1.306
2017-11-28 23:50:05: ['38', '39', '41']->['48'],support=0.023,confidence=0.653,lift=1.365
2017-11-28 23:50:05: ['41']->['39'],support=0.129,confidence=0.764,lift=1.329
2017-11-28 23:50:05: ['79']->['39'],support=0.013,confidence=0.694,lift=1.208
2017-11-28 23:50:05: ['48']->['39'],support=0.331,confidence=0.692,lift=1.203
2017-11-28 23:50:05: ['225']->['39'],support=0.027,confidence=0.722,lift=1.256
2017-11-28 23:50:05: ['32', '41']->['48'],support=0.023,confidence=0.645,lift=1.351
2017-11-28 23:50:05: ['1146']->['39'],support=0.011,confidence=0.689,lift=1.199
2017-11-28 23:50:05: ['101', '39']->['48'],support=0.011,confidence=0.676,lift=1.414
2017-11-28 23:50:05: ['32', '41', '48']->['39'],support=0.019,confidence=0.798,lift=1.388
2017-11-28 23:50:05: ['170']->['38'],support=0.034,confidence=0.978,lift=5.529
2017-11-28 23:50:05: ['36']->['38'],support=0.032,confidence=0.950,lift=5.372
2017-11-28 23:50:05: ['38']->['39'],support=0.117,confidence=0.663,lift=1.154
2017-11-28 23:50:05: ['170', '39']->['38'],support=0.023,confidence=0.981,lift=5.543
2017-11-28 23:50:05: ['170', '39', '48']->['38'],support=0.014,confidence=0.989,lift=5.592
2017-11-28 23:50:05: ['36', '48']->['38'],support=0.015,confidence=0.960,lift=5.429
2017-11-28 23:50:05: ['110', '48']->['39'],support=0.012,confidence=0.751,lift=1.307
2017-11-28 23:50:05: ['170', '38']->['39'],support=0.023,confidence=0.666,lift=1.159
2017-11-28 23:50:05: ['475']->['48'],support=0.016,confidence=0.659,lift=1.379
2017-11-28 23:50:05: ['39', '475']->['48'],support=0.012,confidence=0.728,lift=1.523
2017-11-28 23:50:05: ['270']->['39'],support=0.014,confidence=0.689,lift=1.198
2017-11-28 23:50:05: ['1327']->['39'],support=0.013,confidence=0.647,lift=1.126
2017-11-28 23:50:05: ['475']->['39'],support=0.017,confidence=0.692,lift=1.204
2017-11-28 23:50:05: ['110', '38']->['39'],support=0.020,confidence=0.639,lift=1.111
2017-11-28 23:50:05: ['147']->['39'],support=0.013,confidence=0.639,lift=1.112
2017-11-28 23:50:05: ['36', '38']->['39'],support=0.022,confidence=0.697,lift=1.213
2017-11-28 23:50:05: ['37']->['38'],support=0.012,confidence=0.974,lift=5.506
2017-11-28 23:50:05: ['32', '39']->['48'],support=0.061,confidence=0.639,lift=1.337
2017-11-28 23:50:05: ['170', '38', '48']->['39'],support=0.014,confidence=0.776,lift=1.350
2017-11-28 23:50:05: ['38', '41', '48']->['39'],support=0.023,confidence=0.839,lift=1.459
2017-11-28 23:50:05: ['39', '65']->['48'],support=0.020,confidence=0.645,lift=1.349
2017-11-28 23:50:05: ['286']->['38'],support=0.013,confidence=0.943,lift=5.333
2017-11-28 23:50:05: ['413']->['48'],support=0.013,confidence=0.604,lift=1.263
2017-11-28 23:50:05: ['41', '48']->['39'],support=0.084,confidence=0.817,lift=1.421
2017-11-28 23:50:05: ['39', '41']->['48'],support=0.084,confidence=0.645,lift=1.350
2017-11-28 23:50:05: ['101', '48']->['39'],support=0.011,confidence=0.722,lift=1.255
2017-11-28 23:50:05: ['110', '48']->['38'],support=0.015,confidence=0.986,lift=5.575
2017-11-28 23:50:05: Total time to compute: 6.869274 seconds
--- SharcNET Job Epilogue ---
              job id: 11005340
         exit status: 0
            cpu time: 2142s / 128.0h (0 %)
        elapsed time: 60s / 2.0h (0 %)
      virtual memory: 1.1G / 4.0G (28 %)

Job completed successfully
WARNING: Job only used 0 % of its requested walltime.
WARNING: Job only used 0 % of its requested cpu time.
WARNING: Job only used 55 % of allocated cpu time.
WARNING: Job only used 28% of its requested memory.
